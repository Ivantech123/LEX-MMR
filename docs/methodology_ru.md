# LexMMR™: Методология рейтинга

> **Обратите внимание:** Настоящий документ описывает финальную, целевую методологию системы рейтинга **LexMMR™**. Я, как автор проекта, стремлюсь к максимальной прозрачности и объективности, поэтому публикую эту методологию в первую очередь. 
> 
> Сам программный комплекс и онлайн-сервис находятся в стадии активной итеративной разработки. Некоторые компоненты, описанные здесь, внедряются в данный момент. Я непрерывно работаю над реализацией всех аспектов системы, чтобы обеспечить её надёжность и точность. 
> 
> *С уважением, Иван Андреев.*



> TL;DR: открытые данные + прозрачная формула + минимизация человеческого фактора = объективный рейтинг.

---

## 1. Источники данных

| Блок | Откуда берём | Как получаем |
|------|--------------|--------------|
| Судебные дела | ГАС «Правосудие», sudrf.ru, kartoteka.ru | Headless-скрапинг + RuCaptcha, регулярное обновление cron-парсером |
| Отзывы клиентов | 2GIS, Flamp | REST/HTML-парсер, удаляем накрутку через z-score > 2σ |
| Дисциплинарные меры | Реестры ФПА РФ, сайты палат | HTML-парсер (BeautifulSoup) |
| Медиа-упоминания | NewsAPI.org / Perplexity Web-search | AI-обратка: считаем уникальные публикации за 12 мес. |
| Peer review | Анонимная форма Google / Typeform | ручная модерация + удостоверение email |

Все данные сохраняются в SQLite → можно реплицировать без доступа к закрытым базам.

## 2. Роль ИИ-моделей

1. **Perplexity API** – задаём prompt _«Give me JSON snapshot for …»_, получаем структурированный результат (опыт, громкие дела, медиа-ссылки).
2. **LLM-postprocessing** – ChatGPT 3.5-turbo валидирует outliers, категоризирует типы дел.
3. **Zero-shot классификатор** – модель `RuSentiment` определяет тональность отзывов.

ИИ-модели не «придумывают» рейтинг, а только преобразуют открытые данные → повышают скорость.

## 3. Формула рейтинга (v1.1)

```
final = 0.55 * glicko_norm
       + 0.15 * bayes_win
       + 0.10 * reviews_norm
       + 0.10 * experience_norm
       + 0.05 * media_norm
       + 0.05 * peer_nps_norm
```

### 3.1 Glicko-2
* `rating`, `rd`, `volatility`.  Initial: 1500 ±350.
* Оппонент = сложность дела `complexity ∈ [0.8, 1.4]`.
* Δ вычисляется после каждого решения.

`glicko_norm = clamp((rating-800)/(2400-800), 0,1)`

### 3.2 Bayes Win-rate
```
(wins + 1) / (cases + 2)
```
Сглаживает адвокатов с <5 кейсов.

### 3.3 Reviews
```
(avg_score*n + 3.5*m) / (n+m)  ;  m = 10
```

### 3.4 Experience
```
ln(1 + years)/ln(31)  ∈ [0,1]
```

### 3.5 Media & Peer-NPS
Счётчик уникальных новостей / Net-Promoter-Score коллег, нормируются к 0-1.

## 4. Независимость и открытость

* **Open-source**: весь код MIT-лицензия.  Любой может пересобрать Docker-образ и пересчитать рейтинг.
* **Open data only**: ни одного платного или закрытого источника.
* **Конфиг-весов** расположен в `rating.py::WEIGHTS` – прозрачно.
* **Автоматизация**: ночной cron-pipeline, без ручного «голосования».
* **Верификация**: каждый адвокат может скачать JSON-снимок своего профиля.
* **GDPR / 152-ФЗ**: храним только публично-доступную информацию.

## 5. Расширения (roadmap)

1. Распределённая очередь задач (Celery + Redis).
2. Миграция на PostgreSQL + Timescale для истории рейтинга.
3. UI: доверительный интервал ±RD и график изменения.
4. ML-модель ранжирования win-prob на базе 100k арбитражных дел.


## 6. Расширенная формула рейтинга v2.0 (draft)

> Ниже приведён полный список метрик, весов и формул, к которым мы будем постепенно мигрировать. Раздел предназначен для аналитиков и разработчиков.

### 6.1 Декомпозиция TOTAL

| № | Блок                     | Вес | Состав блока | Формула нормализации |
|---|--------------------------|-----|--------------|----------------------|
| 1 | **Glicko-2**             | **0.45** | rating_norm 0.35, RD_penalty 0.10 | `rating_norm = clamp(100*(r-800)/(2400-800))`, `RD_penalty = max(0,(rd-50)/300)*100` |
| 2 | **Bayes Win-Rate**       | 0.10 | (wins+1)/(cases+2) | напрямую → 0-100 |
| 3 | **Disciplinary**         | 0.08 | Σ warning/ suspension | `Δ·e^(−t/τ)` ; см. 6.4 |
| 4 | **Client Reviews**       | 0.08 | bayes_avg, sentiment_adj | см. 6.5 |
| 5 | **Experience**           | 0.05 | years_norm, court_level_bonus | `ln(1+years)/ln(31)` |
| 6 | **Media Presence**       | 0.05 | uniq_news_12m, tone | лог-норм. |
| 7 | **Peer NPS**            | 0.05 | promoters, detractors | `50+NPS*50` |
| 8 | **Project Size**         | 0.04 | log(sum_dispute_value) | лог-норм. |
| 9 | **Industry Diversity**   | 0.03 | entropy(practice_area) | `H/Hmax` |
|10 | **Education & Certs**    | 0.03 | degree_score, CPD hrs | линейно |
|11 | **Pro-bono & CSR**       | 0.02 | hours_norm | линейно |
|12 | **Awards/Rankings**      | 0.02 | weighted_count | линейно |

`TOTAL = Σ Wi·Fi`, результат 0-100.

### 6.2 Glicko-2 параметры
```
init_rating = 1500, rd = 350, vol = 0.06
τ = 0.5  # volatility constraint
daily update after each decision
```

### 6.3 Trust Index
```
TI = 1 - RD/350  # 0..1
```
Используем как индикатор надёжности: Green >0.7, Yellow 0.4-0.7, Red <0.4.

### 6.4 Disciplinary penalty
| Severity | Δ балла | Период затухания |
|----------|---------|------------------|
| Warning  | −20     | e^(−t/730)       |
| Suspension | −60   | e^(−t/1095)      |

### 6.5 Отзывы клиентов
```
bayes = (avg*n + 3.5*m)/(n+m)  # m = 10 (приор)
sentiment_adj = (pos - neg)*10  # RuSentiment
Fi = clamp(score(bayes)+sentiment_adj, 0,100)
```

### 6.6 Шедулы обновлений
- **daily**: Glicko-2, дисциплинарка, новости.
- **weekly**: перерасчёт Reviews/Sentiment, TOTAL.
- **monthly**: snapshot history, калибровка min/max.

### 6.7 Прозрачность и open data
1. Каждая метрика — ссылка на сырые данные (JSON / CSV).
2. `weights.yml` хранится в репозитории; PR-дискуссии → изменение версии формулы (SemVer).
3. docker-compose делает сборку дет-pipeline без закрытых ключей.

---

## 7. LexMMR™: Детальный разбор для профессионального сообщества

Я представляю **LexMMR™** (от *Lex* — «право» и *Matchmaking Rating*) — динамический, взвешенный и прозрачный индекс для оценки профессиональной деятельности юристов. Моя цель — предоставить коллегам и их потенциальным клиентам объективный инструмент, основанный на публичных данных и защищённый от манипуляций. Ниже приведён детальный разбор каждого компонента.

### 7.1. Судебная практика: Glicko-2, сложность дел и реальные исходы

Это ядро рейтинга, оценивающее не просто количество, а качество судебной работы.

- **Система Glicko-2**: Вместо простого Win/Loss я использую алгоритм, применяемый в шахматах. Он учитывает силу оппонентов: победа над юристом с высоким рейтингом даёт больше очков, чем над новичком. Ключевой элемент — **Rating Deviation (RD)**, или «индекс доверия». Если по юристу мало данных, его RD будет высоким, а рейтинг — нестабильным (система честно признаётся: «я пока не уверен»).

- **ML-классификатор сложности дел**: Я понимаю, что дела неравнозначны. Поэтому я обучил модель машинного обучения (LightGBM) на корпусе из 100 000+ судебных актов, чтобы автоматически присваивать каждому делу коэффициент сложности. Факторы анализа: сумма иска, количество сторон, инстанция, тип спора. Победа в сложном деле ценится выше.

- **Градация исходов**: Я отошёл от бинарной логики «выиграл/проиграл». Система распознаёт и оценивает исходы по-разному:
  - **Полная победа**: +1.0 балла
  - **Частичное удовлетворение иска**: +0.5 балла
  - **Мировое соглашение**: 0 баллов (нейтральный исход)
  - **Поражение**: -1.0 балла

### 7.2. Профессиональная репутация и этика

- **Дисциплинарные взыскания**: Я систематически собираю данные с сайтов региональных палат и ФПА. Поскольку до 30% решений публикуются только в PDF, я использую **OCR-парсер (Tesseract)** для извлечения текста. Механизм работает так:
  - **Присвоение штрафа**: Каждому типу взыскания присваивается отрицательный балл. Например: `замечание = -10`, `предупреждение = -20`, `лишение статуса = -100`.
  - **Временной распад (Decay)**: Штраф не вечен. Его влияние уменьшается линейно в течение определённого периода (например, 24 месяца) и полностью исчезает по его истечении. Формула: `Текущий штраф = Исходный штраф * (1 - (дней с момента взыскания / 730))`. Это мотивирует к исправлению и не ставит крест на репутации навсегда.

- **Отзывы клиентов с защитой от накруток**: Я агрегирую отзывы с публичных площадок (2ГИС, Яндекс.Карты, Flamp). Для борьбы с манипуляциями внедрены два механизма:
  1. **Байесовское сглаживание**: Чтобы один негативный отзыв не обрушил рейтинг нового юриста, мы добавляем к его реальным отзывам несколько «виртуальных» со среднерыночной оценкой (например, 5 отзывов по 3.5 звезды). Формула: `Рейтинг = (Сумма всех оценок + 5 * 3.5) / (Количество отзывов + 5)`. Это делает оценку более стабильной.
  2. **Детектор аномалий**: Алгоритм выявляет подозрительные отзывы, анализируя:
     - **Историю автора**: Аккаунт создан вчера и оставил только один хвалебный отзыв? Подозрительно.
     - **Плотность отзывов**: 10 восторженных отзывов за один день? Вероятно, накрутка.
     - **Содержание**: Слишком короткие («супер!») или шаблонные тексты получают меньший вес.

### 7.3. Квалификация и признание в сообществе

- **Опыт (стаж)**: Учитывается по логарифмической шкале. Это значит, что разница в опыте между 1 и 5 годами более значима для рейтинга, чем между 20 и 25 годами.

- **Медиа-активность**: Система мониторит упоминания юриста в СМИ. Процесс состоит из двух этапов:
  1. **Анализ тональности**: Я использую LLM (через OpenRouter) со специальным промптом, который просит модель не просто классифицировать текст (`позитив/негатив/нейтрально`), но и **обосновать** своё решение, выделив ключевую цитату. Это повышает точность.
  2. **Крауд-валидация**: Рядом с каждой новостью в профиле юриста будет виджет: «Оценка верна? [👍 Да] [👎 Нет]». Если значительное число пользователей (например, >10) не согласны с оценкой ИИ, она автоматически отправляется на ручную модерацию, а её вес в рейтинге временно снижается.

- **Peer-NPS (оценка коллег)**: Я провожу анонимные опросы среди юристов с просьбой порекомендовать (или не порекомендовать) коллег, с которыми они сталкивались в процессах. Чтобы избежать «круговой поруки», влияние этого фактора ограничено и перепроверяется по другим метрикам.

- **Образование, награды, pro-bono**: Учёные степени, публикации, отраслевые награды и подтверждённая бесплатная юридическая помощь (pro-bono) дают дополнительные баллы к рейтингу.

### 7.4. Прозрачность и открытость данных

Я считаю, что доверие к рейтингу невозможно без прозрачности. Поэтому с первого дня запускается **публичный JSON/GraphQL API**. Любой аналитик, журналист или разработчик сможет получить доступ к деперсонализированным сырым данным, на основе которых строится **LexMMR™**, и провести независимый аудит нашей методологии.

Так я создаю не «чёрный ящик», а открытую и проверяемую экосистему.


_Последнее обновление: 04-08-2025._
